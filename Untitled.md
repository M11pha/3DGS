在2020年，NeRF创新性地使用多层感知机作为场景的隐式神经表示，但是其主要的缺点是训练速度很慢，另外基于隐式的场景表示阻碍了其应用到下游任务的发展，2023年3D高斯破溅被首次提出，用于快速且显式地重建三维场景，3DGS使用大量3D高斯椭球描绘3D场景，直接显式优化每个3D高斯椭球的参数并通过投影和α混合进行渲染，其速度很快的主要原因在于充分利用了CUDA的硬件架构，CUDA的硬件架构为分块加块内并发多线程，而3DGS将图像分块，默认大小为16*16，一个像素点对应一个线程

接下来介绍**内窥镜手术场景，左边是一段由达芬奇手术机器人拍摄的视频，内窥镜手术**是微创手术的一种重要类型,而高质量的内窥镜手术场景下的动态三维重建可以促进很多下游任务的发展，比如可视化增强、术中导航、医务人员培训、术前规划、组织分割等，右边是目前主要的基于3DGS的内窥镜手术场景重建方法。这些方法都是基于单视点的视频进行重建，可以把该问题定义为单视点下的动态场景重建问题

第一个创新点是基于规范空间和可逆神经网络设计变形场，此处的规范空间表示类似于生成问题中的隐空间，在其中定义了一组关于该场景的3D高斯椭球，这个规范空间并不明确对应于任何时间步，是一个虚拟空间。然后，定义一个基于可逆神经网络的双射变形场T，建立每一个时间步中的高斯点与规范空间中的高斯点的相互映射。

第二个创新点是对于单目深度估计的改进，出发点在于之前的方法均使用图像深度估计算法，没有考虑视频帧的深度一致性问题。改进方向有两个，使用基于视频的深度估计算法，或者考虑到在图像深度估计中，不同帧中不同像素深度值的顺序是稳定的，引入基于深度顺序的损失函数来进行重建

第三个创新点是**基于帧间光流数据构建**3D流，之前方法对视频帧间关系利用不足，此处利用光流算法，计算出帧间像素的相对位移关系，再结合深度估计信息构建像素的3D流