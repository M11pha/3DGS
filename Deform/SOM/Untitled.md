# Experiment

## 3.1 Experiment Setting

==**Datasets.**==

我们在两个立体内窥镜视频数据集上对方法的有效性进行了定量与定性评估。1）EndoNeRF数据集：包含六个立体手术片段的视频，每个片段包含工具遮挡和一定的组织变形。2）StereoMIS数据集：包含11个立体手术序列。具体来说，我们使用两个可获得的EndoNeRF场景和5个从SrereoMIS数据集中精心选择的切片，这些场景片段涵盖了呼吸，工具运动和不同重建难度的组织变形。

==**Evaluation setting.**== 

我们使用两种评估策略进行实验。1）主视角抽帧对比：遵循以前方法的策略，我们将每个视频帧序列按 7 : 1 的比例划分为训练集和测试集。2）新视角生成对比：我们以左视图（主视图）作为训练集，右视图作为测试集，来对方法进行更为全面的性能评估。此外，先前的方法假设相机固定，为了增强我们方法的鲁棒性，我们不假设场景的相机固定，而是使用Droid-SLAM方法预先估计相机内参和相机外参。由于校准的相机参数不是绝对准确的，渲染结果可能与地面实况在空间上略有错位，因此，我们通过预先训练的光流网络（即 PWC-Net [71]）将渲染结果与地面实况对齐，然后计算对齐结果与地面实况之间的指标，我们使用对齐的PSNR，SSIM和LPIPS作为评估指标。

==**Implementation Details.**==

我们使用 Adam 优化器 [41] 来优化模型。其中，前 1000 次迭代用于初始拟合，之后进行 500 个 epoch 的联合优化。我们一般将手术场景视为全局动态场景，$ \rm{Sim}(3)$ 运动基的数量设为 50-60，在规范空间内初始化10万个高斯，我们采用了与 3D-GS [40] 相同的自适应高斯控制策略。对于分辨率为 512×640、长度为80帧的视频序列，在 4090 GPU 上完成训练大约需要 30分钟。

## 3.2 Comparison with Baselines



##  3.3 Ablations Studies