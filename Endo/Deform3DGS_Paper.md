# Deform3DGS: Flexible Deformation for  Fast Surgical Scene Reconstruction  with Gaussian Splatting

## Abstract

组织变形是精确外科场景重建的关键挑战。尽管现有方法能提供高质量的重建，但它们存在渲染速度慢和训练时间长的问题，限制了其在手术中的应用。受到 3D 高斯 Splatting（一个新兴的实时 3D 渲染技术）近期进展的启发，本工作提出了一种新颖的快速重建框架——Deform3DGS，用于内窥镜手术中可变形组织的重建。具体而言，我们通过将点云初始化引入外科场景，整合 3DGS 来提升重建效果。此外，我们提出了一种新颖的灵活变形建模方案（FDM），用于学习单个高斯层次的组织变形动态。我们的 FDM 可以使用高效的表示建模表面变形，从而实现实时渲染性能。更重要的是，FDM 显著加速了外科场景的重建，展示了其在临床中的重要价值，特别是在手术中，时间效率至关重要。我们在达芬奇机器人手术视频上的实验表明，我们的方法具有较高的重建保真度（PSNR: 37.90）和渲染速度（338.8 FPS），同时大幅缩短了训练时间至每个场景仅 1 分钟。我们的代码可在 https://github.com/jinlab-imvr/Deform3DGS 获取。

Keywords: Fast 3D reconstructon · Surgical scene reconstruction · 3D Gaussian Splatting · Deformable scene.

## 1 Introduction

外科场景的三维（3D）重建在促进许多下游应用方面具有巨大潜力，包括术中导航 [12] 和可视化增强 [13, 9]。此外，具有高质量和动态性的 3D 场景模型已显示出在外科训练中的潜在益处，通过缩短学习曲线 [1] 和远程外科指导 [17]，使得外科场景的沉浸式观察成为可能。

传统的重建方法存在冗余的工作流程，包括深度估计、表面重建和纹理映射 [14]。为了提高紧凑性和效率，许多研究引入了神经辐射场（NeRF）[11]，一种使用小型多层感知器（MLP）的隐式 3D 表示方法，用于从捕获的视频中建模几何细节和外观。该隐式表示可以直接渲染逼真的新视角，简化了传统笨重的工作流程。研究 [15, 20] 成功地将 NeRF 应用于内窥镜场景重建，在渲染质量和几何保真度方面取得了良好的性能。然而，这一系列方法面临长时间训练（数小时）和低渲染速度的问题，这显著限制了它们在手术中的应用。LerPlane [18] 使用分解的 4D 特征平面来编码空间和时间信息，以加速重建。该方法本质上建模了变形，并直接输出用于变形组织的渲染参数，但它严重依赖于在特征平面和 MLP 上执行的复杂计算，从而导致加速效果受到影响。

随着计算机图形学的进展，高斯 Splatting (GS) [5] 成为一种突破性的 3D 表示方法。凭借其卓越的性能，许多研究 [19, 7, 6] 尝试通过变形模型将这一技术应用于动态场景重建，以表示运动。4DGS [16] 是其中的先导研究之一，提出了一种高效的解决方案，使用类似于 [2] 的分解特征平面来建模时间依赖的变形。尽管采用了紧凑的特征编码，4DGS 仍然保留了时间消耗较大的特征平面插值和 MLP 解码，这限制了加速效果和术中应用性。此外，4DGS 未充分利用几何先验，导致点初始化高度稀疏，几何重建时间较长。因此，尽管在动态场景的快速重建中表现出较大优势，将 GS 集成到外科场景重建框架中仍然具有挑战性，这也激发了我们朝着有效地将 GS 适配到术中场景的方向进行研究。

在本文中，我们通过将高斯 Splatting（GS）技术引入外科场景，并结合运动感知点融合（MAPF）密集初始化高斯点云，开发了一种高效的可变形外科场景重建框架——Deform3DGS。此外，我们提出了一种新颖的灵活变形建模方案（FDM），用于高效地表示组织变形。FDM 通过高效的线性组合回归来建模组织变形，其中使用可学习的基函数来提高表示能力和效率。最后，我们在来自达芬奇机器人手术视频的 EndoNeRF [15] 和 StereoMIS [3] 数据集上评估了我们的方法。实验表明，我们的方法有效性显著，展示了优越的重建质量（PSNR: 37.90）和渲染速度（338.8 FPS），同时将训练时间大幅缩短至每个场景约 1 分钟。